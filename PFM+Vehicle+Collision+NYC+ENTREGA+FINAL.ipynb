{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PFM VEHICLE COLLISION\n",
    "\n",
    "## Desde 2011, tras la aprobación de la ley local Nº11, la ciudad de New York publica información relacionada con las colisiones producidas en la ciudad. Esta información se ejecuta manualmente todos los meses y la Unidad TrafficStat revisa la información antes de publicarla en el sitio web del NYPD. \n",
    "\n",
    "## En el dataset contiene más de 400k registros. Cada registro representa una colisión en NYC con información de dia y fecha, barrio, cruce de calles, número de heridos, tipo de vehiculos involucrados y los motivos de la colisión.\n",
    "\n",
    "## Cada año hay más de 170.000 accidentes en la ciudad de NYC en sus cinco distritos: Manhattan, Brooklyn, Staten Island, Bronx y Queens. \n",
    "## Los objetivos del análisis de este dataset son: \n",
    "   ## - \tIdentificar las causas por las que se produce un accidente\n",
    "   ## - \tIdentificar los cruces y zonas más peligrosas\n",
    "   ## - \tIdentificar las zonas más peligrosas o con más colisiones\n",
    "   ## -\tClasificar las localizaciones a través del algoritmo HDBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LIMPIEZA DEL DATASET\n",
    "\n",
    "## Importación de las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import reverse_geocoder as rg\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cargar del fichero con pandas\n",
    "data=pd.read_csv('D:/Mireia D/database.csv',sep=',',parse_dates=['DATE','TIME'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hay 140.000 observaciones sin información de distrito [BOROUGH]. Utilizando algoritmo geocoder reverse, he conseguido completar el 92% de esta información en el dataset, ya que si tenemos las coordenadas de cada observación.\n",
    "## Elimino también todas las observaciones sin localización ya que el objetivo del análisis es encontrar las localizaciones más seguras y peligrosas. \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Eliminar columnas sin localización\n",
    "data=data.dropna(subset=['LOCATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Crear otro datafame solo con información de localiazción y distrito, y elimino los que sí tienen informado el distrito.\n",
    "df_geo=data[['LOCATION','BOROUGH']].copy()\n",
    "df_geo=df_geo[pd.isnull(data['BOROUGH'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Lista de coordenadas para que el algoritmo busque la información del distrito\n",
    "coordenadas = df_geo['LOCATION'].values\n",
    "coordenadas = list(ast.literal_eval(','.join(i.strip() for i in coordenadas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Aplicar la búsqueda de dirección para las coordenadas de nuestro dataset sin info de distrito\n",
    "results = rg.search(coordenadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Crear fichero para guardar la información del distrito y sus coordenadas\n",
    "output_filename = 'D:/Mireia D/Distritos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Rellenar fichero Distritos con la informacion de cada distrito dada unas coordenadas\n",
    "rows = []\n",
    "for idx, city in enumerate(coordenadas):\n",
    "    write_row = []\n",
    "    lat=city[0]\n",
    "    lon=city[1]\n",
    "    gdata = results[idx]\n",
    "    rows.append([lat,lon,gdata['admin2']])\n",
    "csvwriter = csv.writer(open(output_filename,'w+'),delimiter=' ')\n",
    "csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Cargar el fichero con la info de distrito y la unimos al resto de información por accidente\n",
    "distrito=pd.read_csv('D:/Mireia D/Distritos.csv',sep=' ',header=None,low_memory=False)\n",
    "distrito=distrito.rename(columns={0:\"LATITUDE\",1:\"LONGITUDE\",2:\"BOROUGH\",3:\"COORDENADAS\"})\n",
    "distrito['COORDENADAS']=[', '.join(str(x) for x in y) for y in map(tuple, distrito[['LATITUDE', 'LONGITUDE']].values)]\n",
    "distrito=distrito.drop_duplicates(subset=['COORDENADAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Eliminar cuando el distrito que devuelve es Hunterdon county ya que sus coordenadas estan fuera de la ciudad de NY\n",
    "#### Sustituir los barrios que devuelve el algoritmo por los que utiliza el fichero original\n",
    "\n",
    "distrito=distrito[distrito.BOROUGH != 'Hunterdon County']\n",
    "\n",
    "distrito=distrito.replace([\"Queens County\",\"Nassau County\"],'QUEENS')\n",
    "distrito=distrito.replace([\"Kings County\",],'BROOKLYN')\n",
    "distrito=distrito.replace([\"New York County\",\"Bergen County\"],'MANHATTAN')\n",
    "distrito=distrito.replace([\"Bronx\",\"Westchester County\"],'BRONX')\n",
    "distrito=distrito.replace([\"Richmond County\",\"Hudson County\",\"Middlesex County\"],'STATEN ISLAND')\n",
    "distrito[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combinar ambos ficheros\n",
    "result = pd.merge(data, distrito[['LATITUDE','LONGITUDE','BOROUGH']], on=['LATITUDE','LONGITUDE'],how='left')\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Completar BOROUGH_x con BOROUGH:_y\n",
    "result.loc[result['BOROUGH_x'].isnull(),'BOROUGH_x']=result.BOROUGH_y\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Eliminar variable BOROUGH_y del dataframe y renombramos las columnas del dataset\n",
    "#También eliminamos Person injured y person killed porque ya tenemos otras tres columnas que dan esa misma información de manera desagregada.\n",
    "result=result.drop(result.columns[[11,12,29]],axis=1)\n",
    "result.columns=['UNIQUE_KEY','DATE','TIME','BOROUGH','CODE','LATITUDE','LONGITUDE','LOCATION','STREET','CROSS_STREET','OFF_STREET','PEDESTRIAN_INJURED','PEDESTRIAN_KILLED','CYCLIST_INJURED','CYCLIST_KILLED','MOTORIST_INJURED','MOTORIST_KILLED','TYPE_1','TYPE_2','TYPE_3','TYPE_4','TYPE_5','FACTOR_1','FACTOR_2','FACTOR_3','FACTOR_4','FACTOR_5']\n",
    "#Filtrar coordenadas 0,0\n",
    "result=result[result.LATITUDE != 0.0] \n",
    "result=result[result.LONGITUDE != 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Había 47.602 observaciones sin información de ZIP COCE o BOROUGH. Utilizando algoritmo geocoder reverse, he conseguido completar el 92% de esta información en el dataset\n",
    "result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Para analizar si existen dias de la semana, horas del dia o meses más peligrosos, voy a crear estas varaibles en el dataset para facilitar este análissi posterior\n",
    "df=pd.DataFrame(result)\n",
    "\n",
    "df['YEAR']=df['DATE'].dt.year\n",
    "df['MONTH']=df['DATE'].dt.month\n",
    "df['NAMEMONTH']=df['MONTH'].apply(lambda x: calendar.month_abbr[x])\n",
    "df['NAMEWEEK']=df['DATE'].dt.weekday_name\n",
    "df['YEARMONTH'] = df['DATE'].apply(lambda x:x.strftime('%Y-%m'))\n",
    "df['HOUR']=df['TIME'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Se crean variables resumen de heridos y fallecidos por tipo de persona involucrada, con la intención de poder analizar mejor esta información \n",
    "#### Crear variables que sumen el total de personas heridas y fallecidas segun tipo de persona involucrada en el accidente\n",
    "df['PEDESTRIAN']=df['PEDESTRIAN_INJURED'] + df['PEDESTRIAN_KILLED']\n",
    "df['CYCLIST']=df['CYCLIST_INJURED'] + df['CYCLIST_KILLED']\n",
    "df['MOTORIST']=df['MOTORIST_INJURED'] + df['MOTORIST_KILLED']\n",
    "#### Crear variable que sume el total de personas heridas y fallecidas independientemente de si es peaton, conductor o ciclista\n",
    "df['PERSON']=df['PEDESTRIAN'] + df['CYCLIST'] + df['MOTORIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Se crea variable que nos indique el número de vehiculos involucrados en cada accidente \n",
    "#### Crear variable que nos indique el número de vehiculos involucrados\n",
    "type_vehicle=[x for x in df.columns if 'TYPE' in x]\n",
    "df['N_VEHICLE']=df[type_vehicle].apply(lambda x: x.count(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea variable que nos inqique la gravedad del accidente\n",
    "#### clasificando cada accidente en sin heridos, con heridos o con personas fallecidas\n",
    "heridos=[x for x in df.columns if 'INJURED' in x]\n",
    "muertes=[x for x in df.columns if 'KILLED' in x]\n",
    "df['GRAVEDAD']='Sin_heridos'\n",
    "df.loc[df[muertes].sum(axis=1)>0,'GRAVEDAD']='Muertes'\n",
    "df.loc[(df[muertes].sum(axis=1)==0)&(df[heridos].sum(axis=1)>0),'GRAVEDAD']='Heridos'\n",
    "df.GRAVEDAD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalización de los tipos de vehiculos\n",
    "#### Renombrar algunos tipo de vehiculo mal escritos y cambiar a mayusculas\n",
    "for columns in df[type_vehicle]:\n",
    "    df[type_vehicle]=df[type_vehicle].apply(lambda col:col.str.upper())\n",
    "    df[type_vehicle]=df[type_vehicle].replace([\"ABULA\",\"AM\",\"AMB\",\"AMBUL\",\"AR\"],'AMBULANCE')\n",
    "    df[type_vehicle]=df[type_vehicle].replace([\"BU\",\"BSD\"],'BUS')\n",
    "    df[type_vehicle]=df[type_vehicle].replace([\"FB\",\"FDNY\",\"FIRET\",\"FIRE\"],'FIRE TRUCK')\n",
    "    df[type_vehicle]=df[type_vehicle].replace([\"SCOOTER\",\"MOTOR\"],'MOTORCYCLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalización de las calles\n",
    "STREET_GROUP=[x for x in df.columns if 'STREET' in x]\n",
    "for columns in df[STREET_GROUP]:\n",
    "    df[STREET_GROUP]=df[STREET_GROUP].apply(lambda col:col.str.upper())\n",
    "\n",
    "normalization_street={'AVENUE':'AV',\n",
    "    'AVE':'AV',\n",
    "    'AVNUE': 'AV',\n",
    "    'STREET': 'ST',\n",
    "    'ROAD': 'RD',\n",
    "    'BOULEVARD': 'BLVD',\n",
    "    'PLACE': 'PL',\n",
    "    'PLAZA': 'PL',\n",
    "    'SQUARE': 'SQ',\n",
    "    'DRIVE': 'DR',\n",
    "    'LANE': 'LN',\n",
    "    'PARKWAY': 'PKWY',\n",
    "    'TURNPIKE': 'TP',\n",
    "    'TERRACE': 'TER',\n",
    "    '1ST': '1',\n",
    "    '2ND':'2',\n",
    "    '3RD': '3',\n",
    "    '1TH': '1',\n",
    "    '2TH': '2',\n",
    "    '3TH': '3',\n",
    "    '4TH': '4',\n",
    "    '5TH': '5',\n",
    "    '6TH': '6',\n",
    "    '7TH': '7', \n",
    "    '8TH': '8',\n",
    "    '9TH': '9',\n",
    "    '0TH': '0',              \n",
    "    'WEST ': 'W ',\n",
    "    'NORTH ': 'N ',\n",
    "    'EAST ': 'E ',\n",
    "    'SOUTH ': 'S '}\n",
    "\n",
    "#### Realizar reemplazo con los valores de normalización\n",
    "for column in STREET_GROUP:\n",
    "    df[STREET_GROUP]=df[STREET_GROUP].replace(normalization_street,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANÁLISIS EXPLORATORIO \n",
    "## ¿Cuales son los tipos de vehiculo más involucrados en accidentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "df_type = pd.DataFrame([df.loc[:,x].value_counts().nlargest(10) for x in type_vehicle]).fillna(0).sum().sort_values(ascending=True)\n",
    "df_type.plot(kind='barh',ax=ax)\n",
    "ax.set_title('Tipos de vehiculos en accidentes NYC')\n",
    "ax.set_xlabel('Nº accidentes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
